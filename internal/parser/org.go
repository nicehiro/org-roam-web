package parser

import (
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"

	"github.com/niklasfasching/go-org/org"
)

// ToCEntry represents a table of contents entry
type ToCEntry struct {
	Level int
	Title string
	ID    string
}

// ParsedNote contains the parsed content of an org file
type ParsedNote struct {
	Title   string
	Content string // HTML content
	Links   []InternalLink
	Images  []string
	ToC     []ToCEntry
}

// InternalLink represents an internal link to another note
type InternalLink struct {
	ID    string
	Title string
}

// Parser handles org file parsing
type Parser struct {
	roamDir string
	nodeMap map[string]string // ID -> Title mapping
	baseURL string
}

// NewParser creates a new org parser
func NewParser(roamDir string, nodeMap map[string]string, baseURL string) *Parser {
	return &Parser{
		roamDir: roamDir,
		nodeMap: nodeMap,
		baseURL: baseURL,
	}
}

// ParseFile parses an org file and returns HTML content
func (p *Parser) ParseFile(filePath string) (*ParsedNote, error) {
	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to read file: %w", err)
	}

	return p.Parse(string(content), filePath)
}

// Parse parses org content string
func (p *Parser) Parse(content string, filePath string) (*ParsedNote, error) {
	// Extract title from #+title: line
	title := extractTitle(content)

	// Find all internal links before conversion
	links := p.extractInternalLinks(content)

	// Find all images
	images := extractImages(content)

	// Convert LaTeX environments for KaTeX compatibility
	content = convertLatexForKaTeX(content)

	// Convert org to HTML
	doc := org.New().Parse(strings.NewReader(content), filePath)

	// Use custom HTML writer
	writer := newCustomHTMLWriter(p.nodeMap, p.roamDir, p.baseURL)
	html, err := doc.Write(writer)
	if err != nil {
		return nil, fmt.Errorf("failed to convert to HTML: %w", err)
	}

	// Extract just the body content (remove html/head/body tags)
	html = extractBodyContent(html)

	// Remove go-org generated title and ToC from body (we render our own)
	html = stripOrgTitleAndToC(html)

	// Extract table of contents (h2 and h3 only)
	toc := extractToC(html)

	return &ParsedNote{
		Title:   title,
		Content: html,
		Links:   links,
		Images:  images,
		ToC:     toc,
	}, nil
}

// convertLatexForKaTeX converts unsupported LaTeX environments to KaTeX-compatible ones
func convertLatexForKaTeX(content string) string {
	// Convert \begin{align*}...\end{align*} to $$\begin{aligned}...\end{aligned}$$
	re1 := regexp.MustCompile(`\\begin\{align\*\}`)
	content = re1.ReplaceAllString(content, `$$\begin{aligned}`)

	re2 := regexp.MustCompile(`\\end\{align\*\}`)
	content = re2.ReplaceAllString(content, `\end{aligned}$$`)

	// Convert \begin{equation*}...\end{equation*} to $$...$$
	re3 := regexp.MustCompile(`\\begin\{equation\*\}`)
	content = re3.ReplaceAllString(content, `$$`)

	re4 := regexp.MustCompile(`\\end\{equation\*\}`)
	content = re4.ReplaceAllString(content, `$$`)

	// Convert \begin{gather*}...\end{gather*} to $$\begin{gathered}...\end{gathered}$$
	re5 := regexp.MustCompile(`\\begin\{gather\*\}`)
	content = re5.ReplaceAllString(content, `$$\begin{gathered}`)

	re6 := regexp.MustCompile(`\\end\{gather\*\}`)
	content = re6.ReplaceAllString(content, `\end{gathered}$$`)

	return content
}

// stripOrgTitleAndToC removes the go-org generated title and ToC from HTML
// because we render our own title and ToC in the template
func stripOrgTitleAndToC(html string) string {
	// Remove <h1 class="title">...</h1>
	re1 := regexp.MustCompile(`<h1 class="title">[^<]*</h1>\s*`)
	html = re1.ReplaceAllString(html, "")

	// Remove <nav><ul>...</ul></nav> (ToC generated by go-org)
	re2 := regexp.MustCompile(`(?s)<nav>\s*<ul>.*?</ul>\s*</nav>\s*`)
	html = re2.ReplaceAllString(html, "")

	return html
}

// extractToC extracts h2 and h3 headings from HTML content for table of contents
func extractToC(html string) []ToCEntry {
	var toc []ToCEntry

	// Match headline elements generated by go-org
	// Format: <h2 id="headline-1">Title</h2> or <h3 id="headline-2">Title</h3>
	re := regexp.MustCompile(`<h([23])\s+id="(headline-\d+)"[^>]*>([^<]+)</h[23]>`)
	matches := re.FindAllStringSubmatch(html, -1)

	for _, m := range matches {
		if len(m) >= 4 {
			level, _ := strconv.Atoi(m[1])
			toc = append(toc, ToCEntry{
				Level: level,
				Title: strings.TrimSpace(m[3]),
				ID:    m[2],
			})
		}
	}

	return toc
}

// extractTitle extracts the title from #+title: line
func extractTitle(content string) string {
	re := regexp.MustCompile(`(?i)#\+title:\s*(.+)`)
	match := re.FindStringSubmatch(content)
	if len(match) > 1 {
		return strings.TrimSpace(match[1])
	}
	return "Untitled"
}

// extractInternalLinks finds all [[id:...][title]] links
func (p *Parser) extractInternalLinks(content string) []InternalLink {
	var links []InternalLink
	seen := make(map[string]bool)

	// Match [[id:UUID][Title]] or [[id:UUID]]
	re := regexp.MustCompile(`\[\[id:([^\]]+)\](?:\[([^\]]*)\])?\]`)
	matches := re.FindAllStringSubmatch(content, -1)

	for _, m := range matches {
		id := m[1]
		if seen[id] {
			continue
		}
		seen[id] = true

		title := ""
		if len(m) > 2 {
			title = m[2]
		}
		// If no title in link, try to get from nodeMap
		if title == "" {
			if t, ok := p.nodeMap[id]; ok {
				title = t
			}
		}

		links = append(links, InternalLink{
			ID:    id,
			Title: title,
		})
	}

	return links
}

// extractImages finds all image references
func extractImages(content string) []string {
	var images []string
	seen := make(map[string]bool)

	// Match [[file:img/...]] or [[./img/...]]
	re := regexp.MustCompile(`\[\[(?:file:)?([^\]]+\.(?:png|jpg|jpeg|gif|svg|webp))\]\]`)
	matches := re.FindAllStringSubmatch(content, -1)

	for _, m := range matches {
		img := m[1]
		if seen[img] {
			continue
		}
		seen[img] = true
		images = append(images, img)
	}

	return images
}

// extractBodyContent extracts content from HTML body
func extractBodyContent(html string) string {
	// Find content between <body> and </body>
	start := strings.Index(html, "<body>")
	end := strings.Index(html, "</body>")

	if start != -1 && end != -1 {
		return html[start+6 : end]
	}

	// If no body tags, return as-is but remove doctype and html tags
	html = strings.ReplaceAll(html, "<!DOCTYPE html>", "")
	html = strings.ReplaceAll(html, "<html>", "")
	html = strings.ReplaceAll(html, "</html>", "")
	html = strings.ReplaceAll(html, "<head></head>", "")

	return strings.TrimSpace(html)
}

// customHTMLWriter extends the default org HTML writer
type customHTMLWriter struct {
	*org.HTMLWriter
	nodeMap map[string]string
	roamDir string
	baseURL string
}

func newCustomHTMLWriter(nodeMap map[string]string, roamDir string, baseURL string) *customHTMLWriter {
	w := org.NewHTMLWriter()

	cw := &customHTMLWriter{
		HTMLWriter: w,
		nodeMap:    nodeMap,
		roamDir:    roamDir,
		baseURL:    baseURL,
	}

	// Set self as extending writer to override link rendering
	w.ExtendingWriter = cw

	return cw
}

// WriteRegularLink handles link rendering
func (w *customHTMLWriter) WriteRegularLink(l org.RegularLink) {
	url := l.URL
	desc := l.Description

	// Handle id: links
	if strings.HasPrefix(url, "id:") {
		id := strings.TrimPrefix(url, "id:")
		title := ""
		if len(desc) > 0 {
			title = w.getDescriptionText(desc)
		}
		if title == "" {
			if t, ok := w.nodeMap[id]; ok {
				title = t
			} else {
				title = id
			}
		}

		// Write internal link with # prefix
		w.WriteString(fmt.Sprintf(`<a href="%s/notes/%s.html" class="internal-link"><span class="link-marker">#</span> %s</a>`, w.baseURL, id, title))
		return
	}

	// Handle file: links (images)
	if strings.HasPrefix(url, "file:") {
		path := strings.TrimPrefix(url, "file:")
		if isImage(path) {
			// Rewrite image path
			imgPath := w.rewriteImagePath(path)
			w.WriteString(fmt.Sprintf(`<img src="%s" alt="%s" loading="lazy" />`, imgPath, filepath.Base(path)))
			return
		}
	}

	// Handle relative image paths
	if isImage(url) {
		imgPath := w.rewriteImagePath(url)
		w.WriteString(fmt.Sprintf(`<img src="%s" alt="%s" loading="lazy" />`, imgPath, filepath.Base(url)))
		return
	}

	// Default: external link
	descStr := url
	if len(desc) > 0 {
		descStr = w.getDescriptionText(desc)
	}
	w.WriteString(fmt.Sprintf(`<a href="%s" class="external-link" target="_blank" rel="noopener">%s</a>`, url, descStr))
}

// getDescriptionText extracts text from description nodes
func (w *customHTMLWriter) getDescriptionText(desc []org.Node) string {
	var result strings.Builder
	w.extractText(&result, desc)
	return result.String()
}

// extractText recursively extracts text content from nodes
func (w *customHTMLWriter) extractText(result *strings.Builder, nodes []org.Node) {
	for _, n := range nodes {
		switch v := n.(type) {
		case org.Text:
			result.WriteString(v.Content)
		case org.LatexFragment:
			// Reconstruct LaTeX: $\pi_0$ or $$...$$ etc.
			result.WriteString(v.OpeningPair)
			w.extractText(result, v.Content)
			result.WriteString(v.ClosingPair)
		case org.Emphasis:
			// Extract content from bold, italic, etc.
			w.extractText(result, v.Content)
		}
	}
}

// isImage checks if path is an image file
func isImage(path string) bool {
	ext := strings.ToLower(filepath.Ext(path))
	switch ext {
	case ".png", ".jpg", ".jpeg", ".gif", ".svg", ".webp":
		return true
	}
	return false
}

// rewriteImagePath converts org image path to web path
func (w *customHTMLWriter) rewriteImagePath(path string) string {
	// Remove file: prefix if present
	path = strings.TrimPrefix(path, "file:")
	// Remove leading ./ if present
	path = strings.TrimPrefix(path, "./")
	// Ensure it starts with /img/ or similar
	if strings.HasPrefix(path, "img/") {
		return w.baseURL + "/" + path
	}
	return w.baseURL + "/img/" + filepath.Base(path)
}
